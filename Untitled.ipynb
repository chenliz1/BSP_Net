{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import os\n",
    "import h5py\n",
    "import numpy as np  \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from bspnet2D import BspNet2D\n",
    "from loss_func import stage1_loss, rec_loss\n",
    "batchsize = 32\n",
    "epoch = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: <KeysViewHDF5 ['pixels']>\n",
      "Keys: <KeysViewHDF5 ['pixels']>\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('complex_elements.hdf5', 'r') as f:\n",
    "    # List all groups\n",
    "    print(\"Keys: %s\" % f.keys())\n",
    "    a_group_key = list(f.keys())[0]\n",
    "\n",
    "    # Get the data\n",
    "    data = list(f[a_group_key])\n",
    "    \n",
    "    \n",
    "with h5py.File('complex_elements_test.hdf5', 'r') as f:\n",
    "    # List all groups\n",
    "    print(\"Keys: %s\" % f.keys())\n",
    "    a_group_key = list(f.keys())[0]\n",
    "\n",
    "    # Get the data\n",
    "    test_data = list(f[a_group_key])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Length: 2000\n",
      "Testing Dataset Length: 500\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Dataset Length: %d\" % len(data))\n",
    "print(\"Testing Dataset Length: %d\" % len(test_data))\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(data).batch(batchsize)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(test_data).batch(batchsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = BspNet2D(batchsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(net, example, optimizer):\n",
    "    with tf.GradientTape() as tape:\n",
    "        output = net(example)\n",
    "        F = tf.reshape(example, [-1, 64*64, 1])\n",
    "        loss = stage1_loss(output, F, net.decoder.L2.weight, net.decoder.L3.weight) \n",
    "    return loss, tape.gradient(loss, net.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "            \n",
    "def test(net, test_ds):\n",
    "    total_loss = 0\n",
    "    counter = 0\n",
    "    for data in test_ds:\n",
    "        example = tf.cast(data, tf.float32)\n",
    "        F = tf.reshape(example, [-1, 64*64, 1])\n",
    "        S = net(example)\n",
    "        loss = stage1_loss(S, F, net.decoder.L2.weight, net.decoder.L3.weight) \n",
    "        total_loss = (total_loss*counter + loss)/(counter + 1)\n",
    "        counter += 1\n",
    "    return total_loss\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1.697344, shape=(), dtype=float32)\n",
      "Epoch 000: Train_Loss: 1.528, Test_Loss: 1.697\n",
      "Epoch 001: Train_Loss: 1.527, Test_Loss: 1.697\n",
      "Epoch 002: Train_Loss: 1.527, Test_Loss: 1.697\n",
      "Epoch 003: Train_Loss: 1.527, Test_Loss: 1.697\n",
      "Epoch 004: Train_Loss: 1.526, Test_Loss: 1.697\n",
      "Epoch 005: Train_Loss: 1.526, Test_Loss: 1.697\n",
      "Epoch 006: Train_Loss: 1.526, Test_Loss: 1.696\n",
      "Epoch 007: Train_Loss: 1.525, Test_Loss: 1.696\n",
      "Epoch 008: Train_Loss: 1.525, Test_Loss: 1.696\n",
      "Epoch 009: Train_Loss: 1.524, Test_Loss: 1.695\n",
      "Epoch 010: Train_Loss: 1.524, Test_Loss: 1.696\n",
      "Epoch 011: Train_Loss: 1.524, Test_Loss: 1.696\n",
      "Epoch 012: Train_Loss: 1.524, Test_Loss: 1.695\n",
      "Epoch 013: Train_Loss: 1.523, Test_Loss: 1.695\n",
      "Epoch 014: Train_Loss: 1.523, Test_Loss: 1.694\n",
      "Epoch 015: Train_Loss: 1.523, Test_Loss: 1.694\n",
      "Epoch 016: Train_Loss: 1.522, Test_Loss: 1.694\n",
      "Epoch 017: Train_Loss: 1.522, Test_Loss: 1.694\n",
      "Epoch 018: Train_Loss: 1.522, Test_Loss: 1.694\n",
      "Epoch 019: Train_Loss: 1.521, Test_Loss: 1.693\n",
      "Epoch 020: Train_Loss: 1.521, Test_Loss: 1.693\n",
      "Epoch 021: Train_Loss: 1.520, Test_Loss: 1.693\n",
      "Epoch 022: Train_Loss: 1.520, Test_Loss: 1.693\n",
      "Epoch 023: Train_Loss: 1.520, Test_Loss: 1.692\n",
      "Epoch 024: Train_Loss: 1.519, Test_Loss: 1.692\n",
      "Epoch 025: Train_Loss: 1.519, Test_Loss: 1.691\n",
      "Epoch 026: Train_Loss: 1.519, Test_Loss: 1.691\n",
      "Epoch 027: Train_Loss: 1.518, Test_Loss: 1.691\n",
      "Epoch 028: Train_Loss: 1.518, Test_Loss: 1.691\n",
      "Epoch 029: Train_Loss: 1.518, Test_Loss: 1.690\n",
      "Epoch 030: Train_Loss: 1.517, Test_Loss: 1.690\n",
      "Epoch 031: Train_Loss: 1.517, Test_Loss: 1.690\n",
      "Epoch 032: Train_Loss: 1.516, Test_Loss: 1.689\n",
      "Epoch 033: Train_Loss: 1.516, Test_Loss: 1.690\n",
      "Epoch 034: Train_Loss: 1.516, Test_Loss: 1.689\n",
      "Epoch 035: Train_Loss: 1.515, Test_Loss: 1.689\n",
      "Epoch 036: Train_Loss: 1.515, Test_Loss: 1.689\n",
      "Epoch 037: Train_Loss: 1.515, Test_Loss: 1.689\n",
      "Epoch 038: Train_Loss: 1.514, Test_Loss: 1.688\n",
      "Epoch 039: Train_Loss: 1.514, Test_Loss: 1.688\n",
      "Epoch 040: Train_Loss: 1.514, Test_Loss: 1.688\n",
      "Epoch 041: Train_Loss: 1.513, Test_Loss: 1.688\n",
      "Epoch 042: Train_Loss: 1.513, Test_Loss: 1.687\n",
      "Epoch 043: Train_Loss: 1.513, Test_Loss: 1.687\n",
      "Epoch 044: Train_Loss: 1.513, Test_Loss: 1.687\n",
      "Epoch 045: Train_Loss: 1.512, Test_Loss: 1.687\n",
      "Epoch 046: Train_Loss: 1.512, Test_Loss: 1.687\n",
      "Epoch 047: Train_Loss: 1.512, Test_Loss: 1.686\n",
      "Epoch 048: Train_Loss: 1.511, Test_Loss: 1.687\n",
      "Epoch 049: Train_Loss: 1.511, Test_Loss: 1.686\n",
      "Epoch 050: Train_Loss: 1.511, Test_Loss: 1.686\n",
      "Epoch 051: Train_Loss: 1.510, Test_Loss: 1.686\n",
      "Epoch 052: Train_Loss: 1.510, Test_Loss: 1.686\n",
      "Epoch 053: Train_Loss: 1.510, Test_Loss: 1.686\n",
      "Epoch 054: Train_Loss: 1.509, Test_Loss: 1.686\n",
      "Epoch 055: Train_Loss: 1.509, Test_Loss: 1.685\n",
      "Epoch 056: Train_Loss: 1.508, Test_Loss: 1.685\n",
      "Epoch 057: Train_Loss: 1.508, Test_Loss: 1.685\n",
      "Epoch 058: Train_Loss: 1.508, Test_Loss: 1.684\n",
      "Epoch 059: Train_Loss: 1.508, Test_Loss: 1.684\n",
      "Epoch 060: Train_Loss: 1.507, Test_Loss: 1.683\n",
      "Epoch 061: Train_Loss: 1.507, Test_Loss: 1.683\n",
      "Epoch 062: Train_Loss: 1.506, Test_Loss: 1.683\n",
      "Epoch 063: Train_Loss: 1.506, Test_Loss: 1.683\n",
      "Epoch 064: Train_Loss: 1.506, Test_Loss: 1.682\n",
      "Epoch 065: Train_Loss: 1.505, Test_Loss: 1.682\n",
      "Epoch 066: Train_Loss: 1.505, Test_Loss: 1.681\n",
      "Epoch 067: Train_Loss: 1.505, Test_Loss: 1.681\n",
      "Epoch 068: Train_Loss: 1.505, Test_Loss: 1.681\n",
      "Epoch 069: Train_Loss: 1.504, Test_Loss: 1.681\n",
      "Epoch 070: Train_Loss: 1.504, Test_Loss: 1.681\n",
      "Epoch 071: Train_Loss: 1.504, Test_Loss: 1.681\n",
      "Epoch 072: Train_Loss: 1.503, Test_Loss: 1.680\n",
      "Epoch 073: Train_Loss: 1.503, Test_Loss: 1.680\n",
      "Epoch 074: Train_Loss: 1.503, Test_Loss: 1.680\n",
      "Epoch 075: Train_Loss: 1.502, Test_Loss: 1.679\n",
      "Epoch 076: Train_Loss: 1.502, Test_Loss: 1.679\n",
      "Epoch 077: Train_Loss: 1.502, Test_Loss: 1.679\n",
      "Epoch 078: Train_Loss: 1.501, Test_Loss: 1.679\n",
      "Epoch 079: Train_Loss: 1.501, Test_Loss: 1.678\n",
      "Epoch 080: Train_Loss: 1.501, Test_Loss: 1.678\n",
      "Epoch 081: Train_Loss: 1.500, Test_Loss: 1.678\n",
      "Epoch 082: Train_Loss: 1.500, Test_Loss: 1.678\n",
      "Epoch 083: Train_Loss: 1.500, Test_Loss: 1.678\n",
      "Epoch 084: Train_Loss: 1.500, Test_Loss: 1.677\n",
      "Epoch 085: Train_Loss: 1.499, Test_Loss: 1.677\n",
      "Epoch 086: Train_Loss: 1.499, Test_Loss: 1.677\n",
      "Epoch 087: Train_Loss: 1.499, Test_Loss: 1.677\n",
      "Epoch 088: Train_Loss: 1.498, Test_Loss: 1.677\n",
      "Epoch 089: Train_Loss: 1.498, Test_Loss: 1.676\n",
      "Epoch 090: Train_Loss: 1.497, Test_Loss: 1.676\n",
      "Epoch 091: Train_Loss: 1.497, Test_Loss: 1.676\n",
      "Epoch 092: Train_Loss: 1.497, Test_Loss: 1.676\n",
      "Epoch 093: Train_Loss: 1.497, Test_Loss: 1.675\n",
      "Epoch 094: Train_Loss: 1.496, Test_Loss: 1.675\n",
      "Epoch 095: Train_Loss: 1.496, Test_Loss: 1.675\n",
      "Epoch 096: Train_Loss: 1.495, Test_Loss: 1.675\n",
      "Epoch 097: Train_Loss: 1.495, Test_Loss: 1.675\n",
      "Epoch 098: Train_Loss: 1.495, Test_Loss: 1.674\n",
      "Epoch 099: Train_Loss: 1.494, Test_Loss: 1.674\n",
      "Epoch 100: Train_Loss: 1.494, Test_Loss: 1.674\n",
      "Epoch 101: Train_Loss: 1.494, Test_Loss: 1.674\n",
      "Epoch 102: Train_Loss: 1.494, Test_Loss: 1.673\n",
      "Epoch 103: Train_Loss: 1.493, Test_Loss: 1.673\n",
      "Epoch 104: Train_Loss: 1.493, Test_Loss: 1.673\n",
      "Epoch 105: Train_Loss: 1.493, Test_Loss: 1.673\n",
      "Epoch 106: Train_Loss: 1.493, Test_Loss: 1.673\n",
      "Epoch 107: Train_Loss: 1.492, Test_Loss: 1.673\n",
      "Epoch 108: Train_Loss: 1.492, Test_Loss: 1.672\n",
      "Epoch 109: Train_Loss: 1.492, Test_Loss: 1.673\n",
      "Epoch 110: Train_Loss: 1.492, Test_Loss: 1.673\n",
      "Epoch 111: Train_Loss: 1.492, Test_Loss: 1.673\n",
      "Epoch 112: Train_Loss: 1.492, Test_Loss: 1.675\n",
      "Epoch 113: Train_Loss: 1.493, Test_Loss: 1.676\n",
      "Epoch 114: Train_Loss: 1.493, Test_Loss: 1.677\n",
      "Epoch 115: Train_Loss: 1.493, Test_Loss: 1.674\n",
      "Epoch 116: Train_Loss: 1.492, Test_Loss: 1.673\n",
      "Epoch 117: Train_Loss: 1.492, Test_Loss: 1.671\n",
      "Epoch 118: Train_Loss: 1.491, Test_Loss: 1.671\n",
      "Epoch 119: Train_Loss: 1.490, Test_Loss: 1.670\n",
      "Epoch 120: Train_Loss: 1.489, Test_Loss: 1.670\n",
      "Epoch 121: Train_Loss: 1.489, Test_Loss: 1.670\n",
      "Epoch 122: Train_Loss: 1.489, Test_Loss: 1.671\n",
      "Epoch 123: Train_Loss: 1.488, Test_Loss: 1.670\n",
      "Epoch 124: Train_Loss: 1.488, Test_Loss: 1.670\n",
      "Epoch 125: Train_Loss: 1.488, Test_Loss: 1.670\n",
      "Epoch 126: Train_Loss: 1.487, Test_Loss: 1.669\n",
      "Epoch 127: Train_Loss: 1.487, Test_Loss: 1.669\n",
      "Epoch 128: Train_Loss: 1.486, Test_Loss: 1.669\n",
      "Epoch 129: Train_Loss: 1.486, Test_Loss: 1.669\n",
      "Epoch 130: Train_Loss: 1.486, Test_Loss: 1.669\n",
      "Epoch 131: Train_Loss: 1.486, Test_Loss: 1.669\n",
      "Epoch 132: Train_Loss: 1.485, Test_Loss: 1.669\n",
      "Epoch 133: Train_Loss: 1.485, Test_Loss: 1.669\n",
      "Epoch 134: Train_Loss: 1.485, Test_Loss: 1.669\n",
      "Epoch 135: Train_Loss: 1.484, Test_Loss: 1.668\n",
      "Epoch 136: Train_Loss: 1.484, Test_Loss: 1.668\n",
      "Epoch 137: Train_Loss: 1.484, Test_Loss: 1.668\n",
      "Epoch 138: Train_Loss: 1.483, Test_Loss: 1.668\n",
      "Epoch 139: Train_Loss: 1.483, Test_Loss: 1.668\n",
      "Epoch 140: Train_Loss: 1.483, Test_Loss: 1.668\n",
      "Epoch 141: Train_Loss: 1.483, Test_Loss: 1.668\n",
      "Epoch 142: Train_Loss: 1.482, Test_Loss: 1.668\n",
      "Epoch 143: Train_Loss: 1.482, Test_Loss: 1.667\n",
      "Epoch 144: Train_Loss: 1.482, Test_Loss: 1.667\n",
      "Epoch 145: Train_Loss: 1.482, Test_Loss: 1.667\n",
      "Epoch 146: Train_Loss: 1.481, Test_Loss: 1.667\n",
      "Epoch 147: Train_Loss: 1.481, Test_Loss: 1.667\n",
      "Epoch 148: Train_Loss: 1.481, Test_Loss: 1.667\n",
      "Epoch 149: Train_Loss: 1.481, Test_Loss: 1.667\n",
      "Epoch 150: Train_Loss: 1.480, Test_Loss: 1.667\n",
      "Epoch 151: Train_Loss: 1.480, Test_Loss: 1.667\n",
      "Epoch 152: Train_Loss: 1.480, Test_Loss: 1.668\n",
      "Epoch 153: Train_Loss: 1.480, Test_Loss: 1.668\n",
      "Epoch 154: Train_Loss: 1.480, Test_Loss: 1.668\n",
      "Epoch 155: Train_Loss: 1.480, Test_Loss: 1.668\n",
      "Epoch 156: Train_Loss: 1.479, Test_Loss: 1.668\n",
      "Epoch 157: Train_Loss: 1.479, Test_Loss: 1.668\n",
      "Epoch 158: Train_Loss: 1.479, Test_Loss: 1.668\n",
      "Epoch 159: Train_Loss: 1.479, Test_Loss: 1.668\n",
      "Epoch 160: Train_Loss: 1.478, Test_Loss: 1.668\n",
      "Epoch 161: Train_Loss: 1.478, Test_Loss: 1.668\n",
      "Epoch 162: Train_Loss: 1.478, Test_Loss: 1.667\n",
      "Epoch 163: Train_Loss: 1.478, Test_Loss: 1.667\n",
      "Epoch 164: Train_Loss: 1.478, Test_Loss: 1.666\n",
      "Epoch 165: Train_Loss: 1.477, Test_Loss: 1.666\n",
      "Epoch 166: Train_Loss: 1.477, Test_Loss: 1.666\n",
      "Epoch 167: Train_Loss: 1.477, Test_Loss: 1.664\n",
      "Epoch 168: Train_Loss: 1.477, Test_Loss: 1.665\n",
      "Epoch 169: Train_Loss: 1.477, Test_Loss: 1.664\n",
      "Epoch 170: Train_Loss: 1.476, Test_Loss: 1.664\n",
      "Epoch 171: Train_Loss: 1.476, Test_Loss: 1.663\n",
      "Epoch 172: Train_Loss: 1.476, Test_Loss: 1.663\n",
      "Epoch 173: Train_Loss: 1.475, Test_Loss: 1.663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 174: Train_Loss: 1.475, Test_Loss: 1.663\n",
      "Epoch 175: Train_Loss: 1.475, Test_Loss: 1.661\n",
      "Epoch 176: Train_Loss: 1.475, Test_Loss: 1.661\n",
      "Epoch 177: Train_Loss: 1.475, Test_Loss: 1.661\n",
      "Epoch 178: Train_Loss: 1.475, Test_Loss: 1.661\n",
      "Epoch 179: Train_Loss: 1.475, Test_Loss: 1.661\n",
      "Epoch 180: Train_Loss: 1.474, Test_Loss: 1.661\n",
      "Epoch 181: Train_Loss: 1.474, Test_Loss: 1.661\n",
      "Epoch 182: Train_Loss: 1.474, Test_Loss: 1.661\n",
      "Epoch 183: Train_Loss: 1.474, Test_Loss: 1.661\n",
      "Epoch 184: Train_Loss: 1.473, Test_Loss: 1.661\n",
      "Epoch 185: Train_Loss: 1.473, Test_Loss: 1.661\n",
      "Epoch 186: Train_Loss: 1.472, Test_Loss: 1.661\n",
      "Epoch 187: Train_Loss: 1.472, Test_Loss: 1.661\n",
      "Epoch 188: Train_Loss: 1.472, Test_Loss: 1.661\n",
      "Epoch 189: Train_Loss: 1.471, Test_Loss: 1.661\n",
      "Epoch 190: Train_Loss: 1.471, Test_Loss: 1.662\n",
      "Epoch 191: Train_Loss: 1.471, Test_Loss: 1.662\n",
      "Epoch 192: Train_Loss: 1.471, Test_Loss: 1.661\n",
      "Epoch 193: Train_Loss: 1.471, Test_Loss: 1.661\n",
      "Epoch 194: Train_Loss: 1.471, Test_Loss: 1.661\n",
      "Epoch 195: Train_Loss: 1.470, Test_Loss: 1.662\n",
      "Epoch 196: Train_Loss: 1.470, Test_Loss: 1.661\n",
      "Epoch 197: Train_Loss: 1.470, Test_Loss: 1.661\n",
      "Epoch 198: Train_Loss: 1.470, Test_Loss: 1.661\n",
      "Epoch 199: Train_Loss: 1.470, Test_Loss: 1.661\n"
     ]
    }
   ],
   "source": [
    "\n",
    "epoch = 200\n",
    "net.load_weights('stage1_version2_BS32')\n",
    "train_loss_list = []\n",
    "test_loss_list = []\n",
    "prev_test_loss = test(net, test_dataset)\n",
    "print(prev_test_loss)\n",
    "for i in range(epoch):\n",
    "    total_loss = 0\n",
    "    counter = 0\n",
    "    for data in train_dataset:\n",
    "        example = tf.cast(data, tf.float32)\n",
    "        loss, grads = train_step(net, example, opt)\n",
    "        total_loss = (total_loss*counter + loss)/(counter + 1)\n",
    "        counter += 1\n",
    "        opt.apply_gradients(zip(grads, net.trainable_variables))\n",
    "        \n",
    "    test_loss = test(net, test_dataset)\n",
    "    print(\"Epoch {:03d}: Train_Loss: {:.3f}, Test_Loss: {:.3f}\".format(i, total_loss, test_loss))\n",
    "    train_loss_list.append(total_loss)\n",
    "    test_loss_list.append(test_loss)\n",
    "    if test_loss < prev_test_loss:\n",
    "        net.save_weights('stage1_version2_BS32')\n",
    "        prev_test_loss = test_loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1.6607585, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "net.load_weights('stage1_version2_BS32')\n",
    "prev_test_loss = test(net, test_dataset)\n",
    "print(prev_test_loss)\n",
    "em = tf.constant(test_data[10].reshape(1,64,64,1))\n",
    "ps = net(tf.cast(em,dtype=tf.float32))\n",
    "\n",
    "ps = (ps.numpy()).reshape(64,64)\n",
    "em = test_data[10].reshape(64,64)\n",
    "ps[ps>1]=1\n",
    "ps[ps<=0.01]=0\n",
    "# ps[ps>=0.6] = 1\n",
    "# ps[ps<0.6] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8f9c381d50>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(em)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8f9c36fbd0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "net.save_weights('stage1.tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shapes (64, 1) and (256, 64) are incompatible",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-5c252de03adc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'stage1.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch)\u001b[0m\n\u001b[1;32m    232\u001b[0m         raise ValueError('Load weights is not yet supported with TPUStrategy '\n\u001b[1;32m    233\u001b[0m                          'with steps_per_run greater than 1.')\n\u001b[0;32m--> 234\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_mismatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mtrackable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_automatic_dependency_tracking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch)\u001b[0m\n\u001b[1;32m   1220\u001b[0m             f, self.layers, skip_mismatch=skip_mismatch)\n\u001b[1;32m   1221\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1222\u001b[0;31m         \u001b[0mhdf5_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights_from_hdf5_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_updated_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[0;34m(f, layers)\u001b[0m\n\u001b[1;32m    697\u001b[0m                        str(len(weight_values)) + ' elements.')\n\u001b[1;32m    698\u001b[0m     \u001b[0mweight_value_tuples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m   \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m   3321\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3322\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtuples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3323\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3324\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3325\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36massign\u001b[0;34m(self, value, use_locking, name, read_value)\u001b[0m\n\u001b[1;32m    817\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_handle_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m       \u001b[0mvalue_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_is_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m       assign_op = gen_resource_variable_ops.assign_variable_op(\n\u001b[1;32m    821\u001b[0m           self.handle, value_tensor, name=name)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36massert_is_compatible_with\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   1108\u001b[0m     \"\"\"\n\u001b[1;32m   1109\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1110\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Shapes %s and %s are incompatible\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mmost_specific_compatible_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shapes (64, 1) and (256, 64) are incompatible"
     ]
    }
   ],
   "source": [
    "net.load_weights('stage1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
